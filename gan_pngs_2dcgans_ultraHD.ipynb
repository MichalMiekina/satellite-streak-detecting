{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file tic12.fit, as it is not a valid image.\n",
      "Skipping file tic13.fit, as it is not a valid image.\n",
      "Skipping file tic14.fit, as it is not a valid image.\n",
      "Loaded 20 valid images, skipped 3 invalid images.\n",
      "Dataset shape: (20, 256, 256, 3)\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "0 [D loss: 0.7136322259902954, acc.: 25.0] [G loss: 0.4853648543357849]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 929ms/step\n",
      "1 [D loss: 0.6064382195472717, acc.: 50.0] [G loss: 0.18785670399665833]\n",
      "1/1 [==============================] - 1s 903ms/step\n",
      "2 [D loss: 0.5991086035501212, acc.: 50.0] [G loss: 2.323019504547119]\n",
      "1/1 [==============================] - 1s 893ms/step\n",
      "3 [D loss: 0.04241851018741727, acc.: 100.0] [G loss: 6.621248722076416]\n",
      "1/1 [==============================] - 1s 859ms/step\n",
      "4 [D loss: 0.00022463122194269142, acc.: 100.0] [G loss: 6.613015174865723]\n",
      "1/1 [==============================] - 1s 883ms/step\n",
      "5 [D loss: 7.393892246910645e-06, acc.: 100.0] [G loss: 2.8089709281921387]\n",
      "1/1 [==============================] - 1s 870ms/step\n",
      "6 [D loss: 2.315321580681511e-06, acc.: 100.0] [G loss: 0.4079846441745758]\n",
      "1/1 [==============================] - 1s 966ms/step\n",
      "7 [D loss: 2.0241100173734653e-06, acc.: 100.0] [G loss: 0.07495035976171494]\n",
      "1/1 [==============================] - 1s 942ms/step\n",
      "8 [D loss: 1.933937255671503e-06, acc.: 100.0] [G loss: 0.017330750823020935]\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "9 [D loss: 1.9017961676582817e-06, acc.: 100.0] [G loss: 0.010278038680553436]\n",
      "1/1 [==============================] - 1s 873ms/step\n",
      "10 [D loss: 1.385045607094308e-06, acc.: 100.0] [G loss: 0.00958133302628994]\n",
      "1/1 [==============================] - 1s 868ms/step\n",
      "11 [D loss: 1.2308590839897411e-06, acc.: 100.0] [G loss: 0.0035145762376487255]\n",
      "1/1 [==============================] - 1s 900ms/step\n",
      "12 [D loss: 1.0668079539769422e-06, acc.: 100.0] [G loss: 0.003902641125023365]\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "13 [D loss: 1.2491611869366057e-06, acc.: 100.0] [G loss: 0.006287312135100365]\n",
      "1/1 [==============================] - 1s 716ms/step\n",
      "14 [D loss: 1.1443416951860459e-06, acc.: 100.0] [G loss: 0.003255421994253993]\n",
      "1/1 [==============================] - 1s 698ms/step\n",
      "15 [D loss: 1.2772991340355996e-06, acc.: 100.0] [G loss: 0.0026614004746079445]\n",
      "1/1 [==============================] - 1s 777ms/step\n",
      "16 [D loss: 1.8227037799336416e-06, acc.: 100.0] [G loss: 0.0020931155886501074]\n",
      "1/1 [==============================] - 1s 773ms/step\n",
      "17 [D loss: 1.0719134032720391e-06, acc.: 100.0] [G loss: 0.0035406318493187428]\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "18 [D loss: 1.1147645870503395e-06, acc.: 100.0] [G loss: 0.00179489201400429]\n",
      "1/1 [==============================] - 1s 755ms/step\n",
      "19 [D loss: 1.9710275941610847e-06, acc.: 100.0] [G loss: 0.0026011550799012184]\n",
      "1/1 [==============================] - 1s 795ms/step\n",
      "20 [D loss: 9.118076643664088e-07, acc.: 100.0] [G loss: 0.0020995493978261948]\n",
      "1/1 [==============================] - 1s 838ms/step\n",
      "21 [D loss: 9.547341365129247e-07, acc.: 100.0] [G loss: 0.0017375883180648088]\n",
      "1/1 [==============================] - 1s 777ms/step\n",
      "22 [D loss: 1.4974472630768787e-06, acc.: 100.0] [G loss: 0.0023514654021710157]\n",
      "1/1 [==============================] - 1s 715ms/step\n",
      "23 [D loss: 7.808230066075339e-06, acc.: 100.0] [G loss: 0.002001366810873151]\n",
      "1/1 [==============================] - 1s 761ms/step\n",
      "24 [D loss: 8.074106926869717e-05, acc.: 100.0] [G loss: 0.0026439435314387083]\n",
      "1/1 [==============================] - 1s 750ms/step\n",
      "25 [D loss: 0.0124551543144662, acc.: 100.0] [G loss: 25.016891479492188]\n",
      "1/1 [==============================] - 1s 762ms/step\n",
      "26 [D loss: 0.037747226655483246, acc.: 100.0] [G loss: 2.4482740172970807e-06]\n",
      "1/1 [==============================] - 1s 799ms/step\n",
      "27 [D loss: 3.221732414683278e-18, acc.: 100.0] [G loss: 0.02357981912791729]\n",
      "1/1 [==============================] - 1s 854ms/step\n",
      "28 [D loss: 0.7226649522781372, acc.: 95.3125] [G loss: 57.945945739746094]\n",
      "1/1 [==============================] - 1s 827ms/step\n",
      "29 [D loss: 2.28642136335111e-08, acc.: 100.0] [G loss: 107.1818618774414]\n",
      "1/1 [==============================] - 1s 757ms/step\n",
      "30 [D loss: 5.241360391388298, acc.: 50.0] [G loss: 2.1531392230747103e-17]\n",
      "1/1 [==============================] - 1s 750ms/step\n",
      "31 [D loss: 1.9777727127075195, acc.: 70.3125] [G loss: 0.26222264766693115]\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "32 [D loss: 0.16939879152233317, acc.: 90.625] [G loss: 5.174034689733008e-14]\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "33 [D loss: 0.0010380310704961315, acc.: 100.0] [G loss: 4.7127576461359385e-17]\n",
      "1/1 [==============================] - 1s 836ms/step\n",
      "34 [D loss: 0.2518078684806824, acc.: 92.1875] [G loss: 0.032036080956459045]\n",
      "1/1 [==============================] - 1s 770ms/step\n",
      "35 [D loss: 8.98236464319524e-07, acc.: 100.0] [G loss: 9.928838729858398]\n",
      "1/1 [==============================] - 1s 784ms/step\n",
      "36 [D loss: 7.261659666895866, acc.: 54.6875] [G loss: 45.93806838989258]\n",
      "1/1 [==============================] - 1s 824ms/step\n",
      "37 [D loss: 0.37480649359978374, acc.: 76.5625] [G loss: 19.641639709472656]\n",
      "1/1 [==============================] - 1s 767ms/step\n",
      "38 [D loss: 0.3122194299576222, acc.: 95.3125] [G loss: 3.298912525177002]\n",
      "1/1 [==============================] - 1s 794ms/step\n",
      "39 [D loss: 0.45749637903645635, acc.: 73.4375] [G loss: 30.618297576904297]\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "40 [D loss: 0.042589943859048136, acc.: 100.0] [G loss: 35.95579147338867]\n",
      "1/1 [==============================] - 1s 743ms/step\n",
      "41 [D loss: 0.07816392222104884, acc.: 100.0] [G loss: 25.968952178955078]\n",
      "1/1 [==============================] - 1s 793ms/step\n",
      "42 [D loss: 0.011631950027876314, acc.: 100.0] [G loss: 18.180925369262695]\n",
      "1/1 [==============================] - 1s 800ms/step\n",
      "43 [D loss: 0.11674085166305304, acc.: 96.875] [G loss: 26.175853729248047]\n",
      "1/1 [==============================] - 1s 739ms/step\n",
      "44 [D loss: 0.01246699992146727, acc.: 100.0] [G loss: 27.242557525634766]\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "45 [D loss: 0.06208589814923471, acc.: 98.4375] [G loss: 12.32978630065918]\n",
      "1/1 [==============================] - 1s 747ms/step\n",
      "46 [D loss: 0.21603873372077942, acc.: 98.4375] [G loss: 17.180034637451172]\n",
      "1/1 [==============================] - 1s 758ms/step\n",
      "47 [D loss: 0.032072193027563145, acc.: 100.0] [G loss: 17.538158416748047]\n",
      "1/1 [==============================] - 1s 756ms/step\n",
      "48 [D loss: 0.23875593394041061, acc.: 90.625] [G loss: 3.2737295627593994]\n",
      "1/1 [==============================] - 1s 741ms/step\n",
      "49 [D loss: 0.28436299883469474, acc.: 87.5] [G loss: 15.688681602478027]\n",
      "1/1 [==============================] - 1s 701ms/step\n",
      "50 [D loss: 0.0013897109656682005, acc.: 100.0] [G loss: 14.750101089477539]\n",
      "1/1 [==============================] - 1s 786ms/step\n",
      "51 [D loss: 0.01423317715534722, acc.: 100.0] [G loss: 5.086591720581055]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "52 [D loss: 0.170261537656188, acc.: 93.75] [G loss: 11.36471176147461]\n",
      "1/1 [==============================] - 1s 885ms/step\n",
      "53 [D loss: 3.191662073135376, acc.: 9.375] [G loss: 0.4710029065608978]\n",
      "1/1 [==============================] - 1s 882ms/step\n",
      "54 [D loss: 0.17568829865194857, acc.: 89.0625] [G loss: 1.7681667804718018]\n",
      "1/1 [==============================] - 1s 907ms/step\n",
      "55 [D loss: 0.052163124084472656, acc.: 100.0] [G loss: 2.8638927936553955]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "56 [D loss: 0.13694119080901146, acc.: 98.4375] [G loss: 2.221043586730957]\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "57 [D loss: 0.08365158271044493, acc.: 98.4375] [G loss: 3.235053777694702]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "58 [D loss: 0.03995170071721077, acc.: 100.0] [G loss: 2.858152151107788]\n",
      "1/1 [==============================] - 1s 923ms/step\n",
      "59 [D loss: 0.11227625526953489, acc.: 98.4375] [G loss: 5.0769171714782715]\n",
      "1/1 [==============================] - 1s 870ms/step\n",
      "60 [D loss: 0.031239215284585953, acc.: 100.0] [G loss: 3.7514867782592773]\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "61 [D loss: 0.25221285107545555, acc.: 90.625] [G loss: 31.94078254699707]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "62 [D loss: 5.7497250389636605, acc.: 50.0] [G loss: 18.310569763183594]\n",
      "1/1 [==============================] - 1s 998ms/step\n",
      "63 [D loss: 6.536334991455078, acc.: 50.0] [G loss: 17.75959014892578]\n",
      "1/1 [==============================] - 1s 851ms/step\n",
      "64 [D loss: 7.188648637742137e-12, acc.: 100.0] [G loss: 17.147567749023438]\n",
      "1/1 [==============================] - 1s 779ms/step\n",
      "65 [D loss: 0.9100358065840055, acc.: 67.1875] [G loss: 63.173919677734375]\n",
      "1/1 [==============================] - 1s 912ms/step\n",
      "66 [D loss: 14.886577606632192, acc.: 50.0] [G loss: 12.569538116455078]\n",
      "1/1 [==============================] - 1s 747ms/step\n",
      "67 [D loss: 0.6546778082847595, acc.: 70.3125] [G loss: 99.67735290527344]\n",
      "1/1 [==============================] - 1s 868ms/step\n",
      "68 [D loss: 2.939977308675601e-24, acc.: 100.0] [G loss: 79.86053466796875]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "69 [D loss: 1.0122305154800415, acc.: 87.5] [G loss: 9.830472946166992]\n",
      "1/1 [==============================] - 1s 799ms/step\n",
      "70 [D loss: 10.056814193725586, acc.: 50.0] [G loss: 113.26612854003906]\n",
      "1/1 [==============================] - 1s 821ms/step\n",
      "71 [D loss: 6.686647763499996e-11, acc.: 100.0] [G loss: 131.6973876953125]\n",
      "1/1 [==============================] - 1s 813ms/step\n",
      "72 [D loss: 8.418425559997559, acc.: 26.5625] [G loss: 18.544410705566406]\n",
      "1/1 [==============================] - 1s 987ms/step\n",
      "73 [D loss: 0.0046750254301648475, acc.: 100.0] [G loss: 8.238658905029297]\n",
      "1/1 [==============================] - 1s 836ms/step\n",
      "74 [D loss: 0.06575022814219267, acc.: 96.875] [G loss: 4.8838210105896]\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "75 [D loss: 0.018167179866679817, acc.: 100.0] [G loss: 6.131428241729736]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "76 [D loss: 0.10605900498416077, acc.: 96.875] [G loss: 13.452603340148926]\n",
      "1/1 [==============================] - 1s 822ms/step\n",
      "77 [D loss: 0.0004261916019459022, acc.: 100.0] [G loss: 14.969351768493652]\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "78 [D loss: 0.0031729456095490605, acc.: 100.0] [G loss: 8.667314529418945]\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "79 [D loss: 0.045207621762529016, acc.: 98.4375] [G loss: 8.414800643920898]\n",
      "1/1 [==============================] - 1s 812ms/step\n",
      "80 [D loss: 0.1325884386897087, acc.: 98.4375] [G loss: 16.62872314453125]\n",
      "1/1 [==============================] - 1s 838ms/step\n",
      "81 [D loss: 10.688602924346924, acc.: 0.0] [G loss: 2.7625656127929688]\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "82 [D loss: 2.4436040084376636, acc.: 50.0] [G loss: 4.260147571563721]\n",
      "1/1 [==============================] - 1s 761ms/step\n",
      "83 [D loss: 0.11488508325419389, acc.: 95.3125] [G loss: 8.695384979248047]\n",
      "1/1 [==============================] - 1s 773ms/step\n",
      "84 [D loss: 0.006349818781018257, acc.: 100.0] [G loss: 7.5306806564331055]\n",
      "1/1 [==============================] - 1s 938ms/step\n",
      "85 [D loss: 0.07837241049855947, acc.: 98.4375] [G loss: 5.2884626388549805]\n",
      "1/1 [==============================] - 1s 874ms/step\n",
      "86 [D loss: 0.19429244473576546, acc.: 90.625] [G loss: 6.794484615325928]\n",
      "1/1 [==============================] - 1s 836ms/step\n",
      "87 [D loss: 0.5213645100593567, acc.: 76.5625] [G loss: 6.5291619300842285]\n",
      "1/1 [==============================] - 1s 835ms/step\n",
      "88 [D loss: 0.02900895569473505, acc.: 100.0] [G loss: 4.909157752990723]\n",
      "1/1 [==============================] - 1s 848ms/step\n",
      "89 [D loss: 0.013385435566306114, acc.: 100.0] [G loss: 3.4500892162323]\n",
      "1/1 [==============================] - 1s 839ms/step\n",
      "90 [D loss: 0.05260298494249582, acc.: 98.4375] [G loss: 2.4954981803894043]\n",
      "1/1 [==============================] - 1s 837ms/step\n",
      "91 [D loss: 0.12722159456461668, acc.: 100.0] [G loss: 5.875174045562744]\n",
      "1/1 [==============================] - 1s 811ms/step\n",
      "92 [D loss: 3.0990684628486633, acc.: 25.0] [G loss: 0.6191511154174805]\n",
      "1/1 [==============================] - 1s 820ms/step\n",
      "93 [D loss: 0.11413736987742595, acc.: 100.0] [G loss: 4.343003749847412]\n",
      "1/1 [==============================] - 1s 808ms/step\n",
      "94 [D loss: 0.13848542049527168, acc.: 95.3125] [G loss: 3.6334526538848877]\n",
      "1/1 [==============================] - 1s 782ms/step\n",
      "95 [D loss: 0.06199337914586067, acc.: 100.0] [G loss: 2.8234429359436035]\n",
      "1/1 [==============================] - 1s 880ms/step\n",
      "96 [D loss: 0.1038779504597187, acc.: 100.0] [G loss: 2.9112961292266846]\n",
      "1/1 [==============================] - 1s 852ms/step\n",
      "97 [D loss: 0.054548198357224464, acc.: 100.0] [G loss: 3.038590431213379]\n",
      "1/1 [==============================] - 1s 838ms/step\n",
      "98 [D loss: 0.07785093784332275, acc.: 98.4375] [G loss: 2.5109610557556152]\n",
      "1/1 [==============================] - 1s 769ms/step\n",
      "99 [D loss: 0.09244618192315102, acc.: 100.0] [G loss: 2.213757038116455]\n",
      "1/1 [==============================] - 1s 740ms/step\n",
      "1/1 [==============================] - 1s 819ms/step\n",
      "100 [D loss: 0.09388432279229164, acc.: 98.4375] [G loss: 2.1205811500549316]\n",
      "1/1 [==============================] - 1s 803ms/step\n",
      "101 [D loss: 0.11275004968047142, acc.: 98.4375] [G loss: 1.6500529050827026]\n",
      "1/1 [==============================] - 1s 900ms/step\n",
      "102 [D loss: 0.2017064057290554, acc.: 98.4375] [G loss: 2.3816146850585938]\n",
      "1/1 [==============================] - 1s 867ms/step\n",
      "103 [D loss: 0.05674616992473602, acc.: 100.0] [G loss: 3.428473472595215]\n",
      "1/1 [==============================] - 1s 898ms/step\n",
      "104 [D loss: 0.22672343254089355, acc.: 84.375] [G loss: 1.7028071880340576]\n",
      "1/1 [==============================] - 1s 922ms/step\n",
      "105 [D loss: 0.28166454657912254, acc.: 85.9375] [G loss: 4.638748645782471]\n",
      "1/1 [==============================] - 1s 857ms/step\n",
      "106 [D loss: 0.15014666505157948, acc.: 92.1875] [G loss: 2.8947694301605225]\n",
      "1/1 [==============================] - 1s 823ms/step\n",
      "107 [D loss: 0.1054629422724247, acc.: 100.0] [G loss: 2.0625195503234863]\n",
      "1/1 [==============================] - 1s 863ms/step\n",
      "108 [D loss: 0.11985250562429428, acc.: 100.0] [G loss: 2.7589426040649414]\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "109 [D loss: 0.22901557385921478, acc.: 96.875] [G loss: 3.457557201385498]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "110 [D loss: 1.5309571027755737, acc.: 32.8125] [G loss: 5.006153106689453]\n",
      "1/1 [==============================] - 1s 955ms/step\n",
      "111 [D loss: 0.4419492781162262, acc.: 76.5625] [G loss: 1.1069544553756714]\n",
      "1/1 [==============================] - 1s 907ms/step\n",
      "112 [D loss: 0.20676869712769985, acc.: 92.1875] [G loss: 3.2606310844421387]\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "113 [D loss: 0.22592297196388245, acc.: 89.0625] [G loss: 2.0078141689300537]\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "114 [D loss: 0.21959935873746872, acc.: 98.4375] [G loss: 2.766662359237671]\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "115 [D loss: 0.3333069458603859, acc.: 82.8125] [G loss: 2.600414991378784]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "116 [D loss: 0.08382982760667801, acc.: 100.0] [G loss: 4.246352672576904]\n",
      "1/1 [==============================] - 1s 858ms/step\n",
      "117 [D loss: 0.12649289891123772, acc.: 96.875] [G loss: 2.057178020477295]\n",
      "1/1 [==============================] - 1s 813ms/step\n",
      "118 [D loss: 0.13572654873132706, acc.: 100.0] [G loss: 4.207637310028076]\n",
      "1/1 [==============================] - 1s 834ms/step\n",
      "119 [D loss: 0.3213844299316406, acc.: 85.9375] [G loss: 4.843817234039307]\n",
      "1/1 [==============================] - 1s 918ms/step\n",
      "120 [D loss: 0.10097663314081728, acc.: 100.0] [G loss: 1.88795006275177]\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "121 [D loss: 0.25062767043709755, acc.: 95.3125] [G loss: 11.010168075561523]\n",
      "1/1 [==============================] - 1s 845ms/step\n",
      "122 [D loss: 3.024704933166504, acc.: 9.375] [G loss: 2.987525701522827]\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "123 [D loss: 0.6391006894409657, acc.: 56.25] [G loss: 11.388982772827148]\n",
      "1/1 [==============================] - 1s 849ms/step\n",
      "124 [D loss: 3.8574100136756897, acc.: 48.4375] [G loss: 7.719147682189941]\n",
      "1/1 [==============================] - 1s 866ms/step\n",
      "125 [D loss: 0.0060614859976340085, acc.: 100.0] [G loss: 14.331710815429688]\n",
      "1/1 [==============================] - 1s 937ms/step\n",
      "126 [D loss: 0.02592571685090661, acc.: 98.4375] [G loss: 8.926152229309082]\n",
      "1/1 [==============================] - 1s 929ms/step\n",
      "127 [D loss: 1.563261299394071, acc.: 50.0] [G loss: 0.9363301992416382]\n",
      "1/1 [==============================] - 1s 863ms/step\n",
      "128 [D loss: 0.035426187328994274, acc.: 100.0] [G loss: 1.0052518844604492]\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "129 [D loss: 0.04394759610295296, acc.: 100.0] [G loss: 1.264937400817871]\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "130 [D loss: 0.08183648437261581, acc.: 100.0] [G loss: 0.8783498406410217]\n",
      "1/1 [==============================] - 1s 845ms/step\n",
      "131 [D loss: 0.21079028770327568, acc.: 100.0] [G loss: 0.8388254046440125]\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "132 [D loss: 0.3505052477121353, acc.: 89.0625] [G loss: 1.225790023803711]\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "133 [D loss: 0.4521111696958542, acc.: 85.9375] [G loss: 2.0262558460235596]\n",
      "1/1 [==============================] - 1s 867ms/step\n",
      "134 [D loss: 0.2631770521402359, acc.: 90.625] [G loss: 2.7244434356689453]\n",
      "1/1 [==============================] - 1s 735ms/step\n",
      "135 [D loss: 0.28412511944770813, acc.: 92.1875] [G loss: 2.3060343265533447]\n",
      "1/1 [==============================] - 1s 751ms/step\n",
      "136 [D loss: 0.22437480092048645, acc.: 92.1875] [G loss: 1.9349117279052734]\n",
      "1/1 [==============================] - 1s 839ms/step\n",
      "137 [D loss: 0.10483811050653458, acc.: 98.4375] [G loss: 2.2290642261505127]\n",
      "1/1 [==============================] - 1s 880ms/step\n",
      "138 [D loss: 0.18879714608192444, acc.: 96.875] [G loss: 2.3157453536987305]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "139 [D loss: 0.24519021809101105, acc.: 95.3125] [G loss: 2.9221107959747314]\n",
      "1/1 [==============================] - 1s 849ms/step\n",
      "140 [D loss: 0.1866939216852188, acc.: 95.3125] [G loss: 3.2144346237182617]\n",
      "1/1 [==============================] - 1s 850ms/step\n",
      "141 [D loss: 0.265459768474102, acc.: 95.3125] [G loss: 3.1023082733154297]\n",
      "1/1 [==============================] - 1s 858ms/step\n",
      "142 [D loss: 0.09469538182020187, acc.: 96.875] [G loss: 3.3360977172851562]\n",
      "1/1 [==============================] - 1s 828ms/step\n",
      "143 [D loss: 0.09916970506310463, acc.: 96.875] [G loss: 3.07768177986145]\n",
      "1/1 [==============================] - 1s 866ms/step\n",
      "144 [D loss: 0.26782771199941635, acc.: 92.1875] [G loss: 4.421383857727051]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "145 [D loss: 0.14157619327306747, acc.: 93.75] [G loss: 2.9491965770721436]\n",
      "1/1 [==============================] - 1s 987ms/step\n",
      "146 [D loss: 0.15990546345710754, acc.: 100.0] [G loss: 4.012882232666016]\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "147 [D loss: 0.28353970497846603, acc.: 92.1875] [G loss: 3.35866379737854]\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "148 [D loss: 0.22285004705190659, acc.: 95.3125] [G loss: 3.7390036582946777]\n",
      "1/1 [==============================] - 1s 847ms/step\n",
      "149 [D loss: 0.18059593439102173, acc.: 98.4375] [G loss: 3.799854278564453]\n",
      "1/1 [==============================] - 1s 864ms/step\n",
      "150 [D loss: 0.09271833673119545, acc.: 100.0] [G loss: 2.361293315887451]\n",
      "1/1 [==============================] - 1s 993ms/step\n",
      "151 [D loss: 0.029140201397240162, acc.: 100.0] [G loss: 1.8705358505249023]\n",
      "1/1 [==============================] - 1s 934ms/step\n",
      "152 [D loss: 0.09287626761943102, acc.: 100.0] [G loss: 4.403173446655273]\n",
      "1/1 [==============================] - 1s 855ms/step\n",
      "153 [D loss: 0.3427657335996628, acc.: 84.375] [G loss: 3.850693702697754]\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "154 [D loss: 0.023845992051064968, acc.: 100.0] [G loss: 4.2322797775268555]\n",
      "1/1 [==============================] - 1s 857ms/step\n",
      "155 [D loss: 0.2888673320412636, acc.: 93.75] [G loss: 8.27360725402832]\n",
      "1/1 [==============================] - 1s 948ms/step\n",
      "156 [D loss: 1.1744886934757233, acc.: 32.8125] [G loss: 0.9124746918678284]\n",
      "1/1 [==============================] - 1s 904ms/step\n",
      "157 [D loss: 1.9367063573154155, acc.: 50.0] [G loss: 0.9545323848724365]\n",
      "1/1 [==============================] - 1s 801ms/step\n",
      "158 [D loss: 0.09069700352847576, acc.: 100.0] [G loss: 3.1683878898620605]\n",
      "1/1 [==============================] - 1s 790ms/step\n",
      "159 [D loss: 0.2793397381901741, acc.: 92.1875] [G loss: 1.011622428894043]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "160 [D loss: 0.274470791220665, acc.: 98.4375] [G loss: 0.8119024038314819]\n",
      "1/1 [==============================] - 1s 882ms/step\n",
      "161 [D loss: 0.27234116196632385, acc.: 98.4375] [G loss: 1.205552339553833]\n",
      "1/1 [==============================] - 1s 877ms/step\n",
      "162 [D loss: 0.4394889175891876, acc.: 79.6875] [G loss: 1.4189300537109375]\n",
      "1/1 [==============================] - 1s 850ms/step\n",
      "163 [D loss: 0.3340443968772888, acc.: 95.3125] [G loss: 2.0986783504486084]\n",
      "1/1 [==============================] - 1s 864ms/step\n",
      "164 [D loss: 0.30293460190296173, acc.: 92.1875] [G loss: 2.717806816101074]\n",
      "1/1 [==============================] - 1s 859ms/step\n",
      "165 [D loss: 0.3751610666513443, acc.: 85.9375] [G loss: 2.2880029678344727]\n",
      "1/1 [==============================] - 1s 978ms/step\n",
      "166 [D loss: 0.22805920243263245, acc.: 95.3125] [G loss: 2.765254497528076]\n",
      "1/1 [==============================] - 1s 865ms/step\n",
      "167 [D loss: 0.1960357204079628, acc.: 95.3125] [G loss: 2.8403658866882324]\n",
      "1/1 [==============================] - 1s 932ms/step\n",
      "168 [D loss: 0.18971407413482666, acc.: 95.3125] [G loss: 3.2036914825439453]\n",
      "1/1 [==============================] - 1s 850ms/step\n",
      "169 [D loss: 0.33322611451148987, acc.: 89.0625] [G loss: 3.788524627685547]\n",
      "1/1 [==============================] - 1s 978ms/step\n",
      "170 [D loss: 1.1102170050144196, acc.: 34.375] [G loss: 7.8950090408325195]\n",
      "1/1 [==============================] - 1s 856ms/step\n",
      "171 [D loss: 2.946770429611206, acc.: 1.5625] [G loss: 0.370211660861969]\n",
      "1/1 [==============================] - 1s 974ms/step\n",
      "172 [D loss: 0.36637265980243683, acc.: 78.125] [G loss: 1.5370906591415405]\n",
      "1/1 [==============================] - 1s 874ms/step\n",
      "173 [D loss: 0.3867499828338623, acc.: 90.625] [G loss: 1.2386655807495117]\n",
      "1/1 [==============================] - 1s 793ms/step\n",
      "174 [D loss: 0.4252934455871582, acc.: 85.9375] [G loss: 1.2581822872161865]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "175 [D loss: 0.5230157375335693, acc.: 76.5625] [G loss: 0.9960068464279175]\n",
      "1/1 [==============================] - 1s 817ms/step\n",
      "176 [D loss: 0.5914903581142426, acc.: 75.0] [G loss: 1.1225162744522095]\n",
      "1/1 [==============================] - 1s 922ms/step\n",
      "177 [D loss: 0.46842755377292633, acc.: 90.625] [G loss: 1.102701187133789]\n",
      "1/1 [==============================] - 1s 977ms/step\n",
      "178 [D loss: 0.49274110794067383, acc.: 81.25] [G loss: 1.3312441110610962]\n",
      "1/1 [==============================] - 1s 838ms/step\n",
      "179 [D loss: 0.5474716126918793, acc.: 81.25] [G loss: 1.6826307773590088]\n",
      "1/1 [==============================] - 1s 919ms/step\n",
      "180 [D loss: 0.3427201062440872, acc.: 85.9375] [G loss: 2.265500545501709]\n",
      "1/1 [==============================] - 1s 906ms/step\n",
      "181 [D loss: 0.3027458190917969, acc.: 90.625] [G loss: 2.3770110607147217]\n",
      "1/1 [==============================] - 1s 830ms/step\n",
      "182 [D loss: 0.2139451801776886, acc.: 95.3125] [G loss: 2.326695442199707]\n",
      "1/1 [==============================] - 1s 826ms/step\n",
      "183 [D loss: 0.42425931990146637, acc.: 82.8125] [G loss: 1.8104921579360962]\n",
      "1/1 [==============================] - 1s 932ms/step\n",
      "184 [D loss: 0.3743332326412201, acc.: 90.625] [G loss: 1.7927507162094116]\n",
      "1/1 [==============================] - 1s 848ms/step\n",
      "185 [D loss: 0.362276628613472, acc.: 93.75] [G loss: 2.005035877227783]\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "186 [D loss: 0.4508253335952759, acc.: 78.125] [G loss: 2.119548797607422]\n",
      "1/1 [==============================] - 1s 991ms/step\n",
      "187 [D loss: 0.259761244058609, acc.: 93.75] [G loss: 2.21716046333313]\n",
      "1/1 [==============================] - 1s 827ms/step\n",
      "188 [D loss: 0.28335366398096085, acc.: 89.0625] [G loss: 2.2105391025543213]\n",
      "1/1 [==============================] - 1s 835ms/step\n",
      "189 [D loss: 0.12000131304375827, acc.: 96.875] [G loss: 4.002165794372559]\n",
      "1/1 [==============================] - 1s 766ms/step\n",
      "190 [D loss: 0.05031479071476497, acc.: 100.0] [G loss: 5.364134788513184]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "191 [D loss: 0.2966790981590748, acc.: 90.625] [G loss: 2.199434280395508]\n",
      "1/1 [==============================] - 1s 874ms/step\n",
      "192 [D loss: 0.08211197913624346, acc.: 100.0] [G loss: 4.449275493621826]\n",
      "1/1 [==============================] - 1s 791ms/step\n",
      "193 [D loss: 0.43598735332489014, acc.: 90.625] [G loss: 3.439763307571411]\n",
      "1/1 [==============================] - 1s 804ms/step\n",
      "194 [D loss: 0.2518545649945736, acc.: 90.625] [G loss: 2.602914810180664]\n",
      "1/1 [==============================] - 1s 778ms/step\n",
      "195 [D loss: 0.26883145421743393, acc.: 98.4375] [G loss: 3.7103872299194336]\n",
      "1/1 [==============================] - 1s 846ms/step\n",
      "196 [D loss: 0.21439212560653687, acc.: 92.1875] [G loss: 3.1001200675964355]\n",
      "1/1 [==============================] - 1s 797ms/step\n",
      "197 [D loss: 0.3739737719297409, acc.: 87.5] [G loss: 3.8042702674865723]\n",
      "1/1 [==============================] - 1s 852ms/step\n",
      "198 [D loss: 0.39363275468349457, acc.: 82.8125] [G loss: 3.164212942123413]\n",
      "1/1 [==============================] - 1s 722ms/step\n",
      "1/1 [==============================] - 1s 781ms/step\n",
      "199 [D loss: 0.08746133651584387, acc.: 100.0] [G loss: 3.5440003871917725]\n",
      "1/1 [==============================] - 1s 916ms/step\n",
      "200 [D loss: 0.26279444992542267, acc.: 93.75] [G loss: 4.91958475112915]\n",
      "1/1 [==============================] - 1s 874ms/step\n",
      "201 [D loss: 0.36263434030115604, acc.: 70.3125] [G loss: 1.3693764209747314]\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "202 [D loss: 1.1066196616739035, acc.: 51.5625] [G loss: 5.367946624755859]\n",
      "1/1 [==============================] - 1s 830ms/step\n",
      "203 [D loss: 0.32280555239412934, acc.: 76.5625] [G loss: 4.922441482543945]\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "204 [D loss: 0.39251771569252014, acc.: 85.9375] [G loss: 2.8024284839630127]\n",
      "1/1 [==============================] - 1s 782ms/step\n",
      "205 [D loss: 0.15422957949340343, acc.: 90.625] [G loss: 3.2565271854400635]\n",
      "1/1 [==============================] - 1s 778ms/step\n",
      "206 [D loss: 0.14381797215901315, acc.: 98.4375] [G loss: 4.777418613433838]\n",
      "1/1 [==============================] - 1s 759ms/step\n",
      "207 [D loss: 0.43079941533505917, acc.: 70.3125] [G loss: 4.084319114685059]\n",
      "1/1 [==============================] - 1s 800ms/step\n",
      "208 [D loss: 0.1801396929222392, acc.: 98.4375] [G loss: 8.707443237304688]\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "209 [D loss: 0.1441027596592903, acc.: 100.0] [G loss: 2.59352970123291]\n",
      "1/1 [==============================] - 1s 859ms/step\n",
      "210 [D loss: 0.23726928234100342, acc.: 98.4375] [G loss: 3.384298086166382]\n",
      "1/1 [==============================] - 1s 822ms/step\n",
      "211 [D loss: 0.23025714606046677, acc.: 96.875] [G loss: 3.214686870574951]\n",
      "1/1 [==============================] - 1s 859ms/step\n",
      "212 [D loss: 0.16179362684488297, acc.: 93.75] [G loss: 2.880014657974243]\n",
      "1/1 [==============================] - 1s 802ms/step\n",
      "213 [D loss: 0.06856406852602959, acc.: 98.4375] [G loss: 3.9384422302246094]\n",
      "1/1 [==============================] - 1s 823ms/step\n",
      "214 [D loss: 0.06361188739538193, acc.: 100.0] [G loss: 3.3349199295043945]\n",
      "1/1 [==============================] - 1s 950ms/step\n",
      "215 [D loss: 0.05579162575304508, acc.: 100.0] [G loss: 3.619659423828125]\n",
      "1/1 [==============================] - 1s 917ms/step\n",
      "216 [D loss: 0.47218091040849686, acc.: 59.375] [G loss: 8.68625259399414]\n",
      "1/1 [==============================] - 1s 868ms/step\n",
      "217 [D loss: 2.545002371072769, acc.: 10.9375] [G loss: 6.045811176300049]\n",
      "1/1 [==============================] - 1s 872ms/step\n",
      "218 [D loss: 0.86060581356287, acc.: 40.625] [G loss: 2.2227835655212402]\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "219 [D loss: 1.123925268650055, acc.: 42.1875] [G loss: 1.8276857137680054]\n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "220 [D loss: 0.46371643245220184, acc.: 78.125] [G loss: 1.9823293685913086]\n",
      "1/1 [==============================] - 1s 809ms/step\n",
      "221 [D loss: 0.3023996576666832, acc.: 89.0625] [G loss: 1.9562480449676514]\n",
      "1/1 [==============================] - 1s 802ms/step\n",
      "222 [D loss: 0.3247663155198097, acc.: 89.0625] [G loss: 1.564266562461853]\n",
      "1/1 [==============================] - 1s 792ms/step\n",
      "223 [D loss: 0.5071593299508095, acc.: 67.1875] [G loss: 1.4079699516296387]\n",
      "1/1 [==============================] - 1s 800ms/step\n",
      "224 [D loss: 0.34067364037036896, acc.: 95.3125] [G loss: 1.6951298713684082]\n",
      "1/1 [==============================] - 1s 781ms/step\n",
      "225 [D loss: 0.424984410405159, acc.: 85.9375] [G loss: 1.810887098312378]\n",
      "1/1 [==============================] - 1s 806ms/step\n",
      "226 [D loss: 0.3281674087047577, acc.: 96.875] [G loss: 1.9828780889511108]\n",
      "1/1 [==============================] - 1s 929ms/step\n",
      "227 [D loss: 0.3936045169830322, acc.: 85.9375] [G loss: 2.1504743099212646]\n",
      "1/1 [==============================] - 1s 739ms/step\n",
      "228 [D loss: 0.30304914712905884, acc.: 93.75] [G loss: 2.3633456230163574]\n",
      "1/1 [==============================] - 1s 816ms/step\n",
      "229 [D loss: 0.31905919313430786, acc.: 95.3125] [G loss: 2.00105357170105]\n",
      "1/1 [==============================] - 1s 822ms/step\n",
      "230 [D loss: 0.35639454424381256, acc.: 93.75] [G loss: 2.5144705772399902]\n",
      "1/1 [==============================] - 1s 876ms/step\n",
      "231 [D loss: 0.4854603409767151, acc.: 81.25] [G loss: 1.5766592025756836]\n",
      "1/1 [==============================] - 1s 957ms/step\n",
      "232 [D loss: 0.23990314453840256, acc.: 98.4375] [G loss: 1.5173616409301758]\n",
      "1/1 [==============================] - 1s 939ms/step\n",
      "233 [D loss: 0.4096430838108063, acc.: 92.1875] [G loss: 2.248757839202881]\n",
      "1/1 [==============================] - 1s 749ms/step\n",
      "234 [D loss: 1.0300092697143555, acc.: 15.625] [G loss: 2.5900588035583496]\n",
      "1/1 [==============================] - 1s 898ms/step\n",
      "235 [D loss: 0.1263948231935501, acc.: 100.0] [G loss: 3.048982620239258]\n",
      "1/1 [==============================] - 1s 836ms/step\n",
      "236 [D loss: 0.4338446408510208, acc.: 84.375] [G loss: 1.5990824699401855]\n",
      "1/1 [==============================] - 1s 827ms/step\n",
      "237 [D loss: 0.1522778794169426, acc.: 100.0] [G loss: 2.0999755859375]\n",
      "1/1 [==============================] - 1s 829ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import UnidentifiedImageError\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder paths\n",
    "input_folder = './Data/fits_filtered2'\n",
    "output_folder = './Data/fits_filtered2/DoubleDCGan1000epochsOnlyStreaks_ultraHD'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Flag for using only files with label 1\n",
    "use_label_1_only = True\n",
    "\n",
    "# Step 1: Load and Filter Images Based on Labels\n",
    "def load_images_with_labels(folder, csv_file, image_size=(64, 64), use_label_1_only=True):\n",
    "    images = []\n",
    "    valid_files = 0\n",
    "    invalid_files = 0\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        label_data = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"CSV file '{csv_file}' not found in the folder '{folder}'.\")\n",
    "\n",
    "    # Filter files based on label if the flag is set\n",
    "    if use_label_1_only:\n",
    "        label_data = label_data[label_data['label'] == 1]\n",
    "\n",
    "    # Load images\n",
    "    for _, row in label_data.iterrows():\n",
    "        filename = row['output']\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = load_img(file_path, target_size=image_size)\n",
    "            images.append(img_to_array(img))\n",
    "            valid_files += 1\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            print(f\"Skipping file {filename}, as it is not a valid image.\")\n",
    "            invalid_files += 1\n",
    "\n",
    "    print(f\"Loaded {valid_files} valid images, skipped {invalid_files} invalid images.\")\n",
    "    return np.array(images)\n",
    "\n",
    "# Load dataset\n",
    "csv_file_path = os.path.join(input_folder, 'dictionary_0.csv')\n",
    "dataset = load_images_with_labels(input_folder, csv_file_path, image_size=(256, 256), use_label_1_only=use_label_1_only)\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "if dataset.size == 0:\n",
    "    raise ValueError(\"No valid images found in the dataset. Please check the image files or the CSV labels.\")\n",
    "dataset = (dataset - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(1024 * 4 * 4, activation=\"relu\", input_dim=100))  # Start with a smaller initial feature map\n",
    "    model.add(layers.Reshape((4, 4, 1024)))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.UpSampling2D())  # 8x8\n",
    "    model.add(layers.Conv2D(512, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())  # 16x16\n",
    "    model.add(layers.Conv2D(256, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())  # 32x32\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())  # 64x64\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())  # 128x128\n",
    "    model.add(layers.Conv2D(32, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())  # 256x256\n",
    "    model.add(layers.Conv2D(3, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.Activation(\"tanh\"))\n",
    "    return model\n",
    "\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, input_shape=(256, 256, 3), padding=\"same\"))  # 256x256 -> 128x128\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))  # 128x128 -> 64x64\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))  # 64x64 -> 32x32\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(512, kernel_size=4, strides=2, padding=\"same\"))  # 32x32 -> 16x16\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(1024, kernel_size=4, strides=2, padding=\"same\"))  # 16x16 -> 8x8\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(2048, kernel_size=4, strides=2, padding=\"same\"))  # 8x8 -> 4x4\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# Stack generator and discriminator\n",
    "z = layers.Input(shape=(100,))\n",
    "img = generator(z)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(img)\n",
    "combined = tf.keras.Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "# Step 3: Train the GAN\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "save_interval = 99\n",
    "X_train = dataset\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs = X_train[idx]\n",
    "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid_y = np.array([1] * batch_size)\n",
    "    g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "    print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        noise = np.random.normal(0, 1, (25, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        fig, axs = plt.subplots(5, 5)\n",
    "        cnt = 0\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                axs[i, j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.savefig(os.path.join(output_folder, f'epoch_{epoch}.png'))\n",
    "        plt.close()\n",
    "\n",
    "# Generate new images\n",
    "noise = np.random.normal(0, 1, (10, 100))\n",
    "gen_imgs = generator.predict(noise)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "for i in range(10):\n",
    "    plt.imshow(gen_imgs[i])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_folder, f'final_{i}.png'))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
