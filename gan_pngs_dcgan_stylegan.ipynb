{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file augmented, as it is not a valid image.\n",
      "Skipping file DCGAN_generated_imagesXD, as it is not a valid image.\n",
      "Skipping file dictionary_0.csv, as it is not a valid image.\n",
      "Skipping file DoubleDCGan, as it is not a valid image.\n",
      "Skipping file generated_images, as it is not a valid image.\n",
      "Skipping file generated_images2, as it is not a valid image.\n",
      "Skipping file generated_images3, as it is not a valid image.\n",
      "Skipping file generated_images4, as it is not a valid image.\n",
      "Skipping file generated_images5, as it is not a valid image.\n",
      "Skipping file generated_images6, as it is not a valid image.\n",
      "Skipping file generated_imagesPG-GAN, as it is not a valid image.\n",
      "Skipping file generated_imagesProgressiveDCGAN, as it is not a valid image.\n",
      "Skipping file StyleGAN_generated_images, as it is not a valid image.\n",
      "Skipping file StyleGAN_generated_images1000epochs, as it is not a valid image.\n",
      "Skipping file StyleGAN_generated_images2, as it is not a valid image.\n",
      "Skipping file StyleGAN_generated_images3, as it is not a valid image.\n",
      "Skipping file timeCounter, as it is not a valid image.\n",
      "Loaded 140 valid images, skipped 17 invalid images.\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "0/10 [D loss: 0.6992517113685608, acc.: 0.00%] [G loss: 0.6943069696426392]\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/10 [D loss: 0.6736849546432495, acc.: 50.00%] [G loss: 0.6718577146530151]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "2/10 [D loss: 0.6540422141551971, acc.: 50.00%] [G loss: 0.6557724475860596]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "3/10 [D loss: 0.6319013833999634, acc.: 50.00%] [G loss: 0.6425739526748657]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "4/10 [D loss: 0.6147046685218811, acc.: 50.00%] [G loss: 0.6233497262001038]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "5/10 [D loss: 0.6038202047348022, acc.: 50.00%] [G loss: 0.5978626012802124]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "6/10 [D loss: 0.6113813817501068, acc.: 50.00%] [G loss: 0.5773069858551025]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "7/10 [D loss: 0.6226969957351685, acc.: 50.00%] [G loss: 0.5561091899871826]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "8/10 [D loss: 0.638190507888794, acc.: 50.00%] [G loss: 0.5360791683197021]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "9/10 [D loss: 0.6602554172277451, acc.: 50.00%] [G loss: 0.5376413464546204]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "# Create output folder for generated images\n",
    "output_folder = './Data/fits_filtered2/timecounter'\n",
    "# output_folder = './Data/fits_filtered2/augmented/StyleGAN_generated_images1000epochs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load and preprocess dataset\n",
    "def load_images_from_folder(folder, image_size=(64, 64)):\n",
    "    images = []\n",
    "    valid_files = 0\n",
    "    invalid_files = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            img = load_img(os.path.join(folder, filename), target_size=image_size)\n",
    "            if img is not None:\n",
    "                images.append(img_to_array(img))\n",
    "                valid_files += 1\n",
    "            else:\n",
    "                invalid_files += 1\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            print(f\"Skipping file {filename}, as it is not a valid image.\")\n",
    "            invalid_files += 1\n",
    "    print(f\"Loaded {valid_files} valid images, skipped {invalid_files} invalid images.\")\n",
    "    return np.array(images)\n",
    "\n",
    "dataset = load_images_from_folder('./Data/fits_filtered2')\n",
    "if dataset.size == 0:\n",
    "    raise ValueError(\"No valid images found in the dataset.\")\n",
    "dataset = (dataset - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "\n",
    "# Mapping Network\n",
    "def mapping_network(latent_dim=100, num_layers=8):\n",
    "    inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = inputs\n",
    "    for _ in range(num_layers):\n",
    "        x = layers.Dense(latent_dim, activation=\"relu\")(x)\n",
    "    return tf.keras.Model(inputs, x, name=\"MappingNetwork\")\n",
    "\n",
    "# Adaptive Instance Normalization (AdaIN)\n",
    "def adain(x, w):\n",
    "    mean, var = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "    std = tf.sqrt(var + 1e-8)\n",
    "    gamma = layers.Dense(x.shape[-1])(w)\n",
    "    beta = layers.Dense(x.shape[-1])(w)\n",
    "    gamma = tf.reshape(gamma, [-1, 1, 1, x.shape[-1]])\n",
    "    beta = tf.reshape(beta, [-1, 1, 1, x.shape[-1]])\n",
    "    return gamma * (x - mean) / std + beta\n",
    "\n",
    "# StyleGAN Generator\n",
    "def build_stylegan_generator(latent_dim=100, initial_resolution=8, target_resolution=64):\n",
    "    w_input = layers.Input(shape=(latent_dim,))\n",
    "    resolution = initial_resolution\n",
    "    x = layers.Dense(resolution * resolution * 256, activation=\"relu\")(w_input)\n",
    "    x = layers.Reshape((resolution, resolution, 256))(x)\n",
    "\n",
    "    while resolution < target_resolution:\n",
    "        resolution *= 2\n",
    "        x = layers.UpSampling2D()(x)\n",
    "        x = layers.Conv2D(256 // (resolution // 8), kernel_size=3, padding=\"same\")(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "        x = adain(x, w_input)\n",
    "\n",
    "    output = layers.Conv2D(3, kernel_size=1, activation=\"tanh\")(x)\n",
    "    return tf.keras.Model(w_input, output, name=\"StyleGANGenerator\")\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator(target_resolution=64):\n",
    "    inputs = layers.Input(shape=(target_resolution, target_resolution, 3))\n",
    "    x = inputs\n",
    "    while x.shape[1] > 4:\n",
    "        x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inputs, output, name=\"StyleGANDiscriminator\")\n",
    "\n",
    "# Initialize networks\n",
    "latent_dim = 100\n",
    "mapping = mapping_network(latent_dim=latent_dim)\n",
    "generator = build_stylegan_generator(latent_dim=latent_dim)\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "# Compile discriminator\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=[\"accuracy\"])\n",
    "\n",
    "# Combined model\n",
    "z = layers.Input(shape=(latent_dim,))\n",
    "w = mapping(z)\n",
    "img = generator(w)\n",
    "discriminator.trainable = False\n",
    "valid = discriminator(img)\n",
    "combined = tf.keras.Model(z, valid)\n",
    "combined.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "# Train StyleGAN\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "save_interval = 1\n",
    "half_batch = batch_size // 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train discriminator\n",
    "    idx = np.random.randint(0, dataset.shape[0], half_batch)\n",
    "    imgs = dataset[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (half_batch, latent_dim))\n",
    "    w = mapping.predict(noise)\n",
    "    gen_imgs = generator.predict(w)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    print(f\"{epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]:.2f}%] [G loss: {g_loss}]\")\n",
    "\n",
    "    # Save generated images at intervals\n",
    "    if epoch % save_interval == 0:\n",
    "        noise = np.random.normal(0, 1, (25, latent_dim))\n",
    "        w = mapping.predict(noise)\n",
    "        gen_imgs = generator.predict(w)\n",
    "\n",
    "        # Rescale images from [-1, 1] to [0, 1]\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        # Create a 5x5 grid to save the images\n",
    "        fig, axs = plt.subplots(5, 5)\n",
    "        cnt = 0\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                axs[i, j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        \n",
    "        # Save the grid as a PNG file\n",
    "        fig.savefig(os.path.join(output_folder, f\"epoch_{epoch}.png\"))\n",
    "        plt.close()  # Close the figure to free up memory\n",
    "\n",
    "# Save final single images\n",
    "noise = np.random.normal(0, 1, (10, latent_dim))\n",
    "w = mapping.predict(noise)\n",
    "gen_imgs = generator.predict(w)\n",
    "\n",
    "# Rescale images from [-1, 1] to [0, 1]\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(gen_imgs[i])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_folder, f'final_{i}.png'))  # Save final individual images\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
