{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading augmented: [Errno 13] Permission denied: './Data/fits_filtered4\\\\augmented'\n",
      "Error loading data: [Errno 13] Permission denied: './Data/fits_filtered4\\\\data'\n",
      "Error loading dictionary_0.csv: cannot identify image file <_io.BytesIO object at 0x0000011A498F9F80>\n",
      "Error loading gan_output1: [Errno 13] Permission denied: './Data/fits_filtered4\\\\gan_output1'\n",
      "Error loading gan_output2: [Errno 13] Permission denied: './Data/fits_filtered4\\\\gan_output2'\n",
      "Loaded 47 valid images, skipped 5 invalid images.\n",
      "Dataset shape: (47, 128, 128, 3)\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "0 [D loss: 0.07077676057815552, acc.: 31.25] [G loss: 0.5034868717193604]\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1 [D loss: -0.199498750269413, acc.: 0.0] [G loss: 0.5362001657485962]\n",
      "1/1 [==============================] - 0s 286ms/step\n",
      "2 [D loss: -0.3538418374955654, acc.: 0.0] [G loss: 0.6114389896392822]\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "3 [D loss: -0.4283123165369034, acc.: 0.0] [G loss: 0.6722100973129272]\n",
      "1/1 [==============================] - 0s 292ms/step\n",
      "4 [D loss: -0.45474932342767715, acc.: 0.0] [G loss: 0.7048105001449585]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "5 [D loss: -0.4708592966198921, acc.: 0.0] [G loss: 0.708672046661377]\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "6 [D loss: -0.4773478526622057, acc.: 0.0] [G loss: 0.7067350149154663]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "7 [D loss: -0.48083213390782475, acc.: 0.0] [G loss: 0.7271676063537598]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "8 [D loss: -0.4832431813701987, acc.: 0.0] [G loss: 0.6635086536407471]\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "9 [D loss: -0.4854062148369849, acc.: 0.0] [G loss: 0.6762820482254028]\n",
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import UnidentifiedImageError\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "# Create a nested folder for the generated images\n",
    "# output_folder = './Data/fits_filtered9/augmented_images/gan_output2'\n",
    "output_folder = './Data/fits_filtered4/gan_output1'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Step 1: Load and Preprocess Dataset\n",
    "def load_images_from_folder(folder, image_size=(128, 128)):\n",
    "    images = []\n",
    "    valid_files, invalid_files = 0, 0\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            img = load_img(os.path.join(folder, filename), target_size=image_size)\n",
    "            if img is not None:\n",
    "                images.append(img_to_array(img))\n",
    "                valid_files += 1\n",
    "        except (UnidentifiedImageError, OSError) as e:\n",
    "            print(f\"Error loading {filename}: {e}\")\n",
    "            invalid_files += 1\n",
    "    print(f\"Loaded {valid_files} valid images, skipped {invalid_files} invalid images.\")\n",
    "    return np.array(images)\n",
    "\n",
    "# dataset = load_images_from_folder('./Data/fits_filtered9/augmented_images')\n",
    "dataset = load_images_from_folder('./Data/fits_filtered4')\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "if dataset.size == 0:\n",
    "    raise ValueError(\"No valid images found in the dataset. Please check the image files.\")\n",
    "dataset = (dataset - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "\n",
    "# Step 2: Build the GAN\n",
    "# Generator\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(512 * 8 * 8, activation=\"relu\", input_dim=100),\n",
    "        layers.Reshape((8, 8, 512)),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.UpSampling2D(),  # 16x16\n",
    "        layers.Conv2D(256, kernel_size=3, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.UpSampling2D(),  # 32x32\n",
    "        layers.Conv2D(128, kernel_size=3, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.UpSampling2D(),  # 64x64\n",
    "        layers.Conv2D(64, kernel_size=3, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.Activation(\"relu\"),\n",
    "        layers.UpSampling2D(),  # 128x128\n",
    "        layers.Conv2D(3, kernel_size=3, padding=\"same\"),\n",
    "        layers.Activation(\"tanh\")\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, kernel_size=3, strides=2, input_shape=(128, 128, 3), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(256, kernel_size=3, strides=2, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Conv2D(512, kernel_size=3, strides=2, padding=\"same\"),\n",
    "        layers.BatchNormalization(momentum=0.8),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)\n",
    "\n",
    "# Load VGG19 model for perceptual loss\n",
    "vgg = VGG19(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
    "vgg.trainable = False\n",
    "perceptual_model = tf.keras.Model(inputs=vgg.input, outputs=vgg.get_layer('block5_conv4').output)\n",
    "\n",
    "# Perceptual loss\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    y_true_features = perceptual_model(y_true)\n",
    "    y_pred_features = perceptual_model(y_pred)\n",
    "    return K.mean(K.square(y_true_features - y_pred_features))\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss=wasserstein_loss, optimizer=tf.keras.optimizers.Adam(0.0001, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates images\n",
    "z = layers.Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model, only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model (stacked generator and discriminator)\n",
    "combined = tf.keras.Model(z, valid)\n",
    "combined.compile(loss=wasserstein_loss, optimizer=tf.keras.optimizers.Adam(0.0001, 0.5))\n",
    "\n",
    "# Step 3: Train the GAN\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "save_interval = 10\n",
    "\n",
    "X_train = dataset\n",
    "half_batch = max(1, batch_size // 2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, -np.ones((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "    print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "    if epoch % save_interval == 0:\n",
    "        noise = np.random.normal(0, 1, (25, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "        fig, axs = plt.subplots(5, 5)\n",
    "        cnt = 0\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                axs[i, j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.suptitle(f'Epoch {epoch}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder, f'epoch_{epoch}.png'))\n",
    "        plt.close()\n",
    "\n",
    "        generator.save(f'generator_epoch_{epoch}.h5')\n",
    "        discriminator.save(f'discriminator_epoch_{epoch}.h5')\n",
    "\n",
    "# Final image generation\n",
    "noise = np.random.normal(0, 1, (10, 100))\n",
    "gen_imgs = generator.predict(noise)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(gen_imgs[i])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_folder, f'final_{i}.png'))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
