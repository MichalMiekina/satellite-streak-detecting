{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file augmented, as it is not a valid image.\n",
      "Skipping file dictionary_0.csv, as it is not a valid image.\n",
      "Skipping file generated_images, as it is not a valid image.\n",
      "Skipping file generated_images2, as it is not a valid image.\n",
      "Skipping file generated_images3, as it is not a valid image.\n",
      "Skipping file generated_images4, as it is not a valid image.\n",
      "Skipping file generated_images5, as it is not a valid image.\n",
      "Skipping file generated_images6, as it is not a valid image.\n",
      "Skipping file timeCounter, as it is not a valid image.\n",
      "Loaded 140 valid images, skipped 9 invalid images.\n",
      "Dataset shape: (140, 64, 64, 3)\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "0 [D loss: 0.6804648041725159, acc.: 42.1875] [G loss: 0.6037784218788147]\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "1 [D loss: 0.5899256318807602, acc.: 50.0] [G loss: 0.534724771976471]\n",
      "1/1 [==============================] - 0s 280ms/step\n",
      "2 [D loss: 0.5520539730787277, acc.: 50.0] [G loss: 0.47706860303878784]\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "3 [D loss: 0.46653924882411957, acc.: 50.0] [G loss: 0.40231484174728394]\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "4 [D loss: 0.3275800496339798, acc.: 100.0] [G loss: 0.26865649223327637]\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "5 [D loss: 0.15635669976472855, acc.: 100.0] [G loss: 0.11082116514444351]\n",
      "1/1 [==============================] - 0s 269ms/step\n",
      "6 [D loss: 0.04007212445139885, acc.: 100.0] [G loss: 0.030067328363656998]\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "7 [D loss: 0.01133200153708458, acc.: 100.0] [G loss: 0.009366986341774464]\n",
      "1/1 [==============================] - 0s 265ms/step\n",
      "8 [D loss: 0.005242714425548911, acc.: 100.0] [G loss: 0.003946049138903618]\n",
      "1/1 [==============================] - 0s 294ms/step\n",
      "9 [D loss: 0.0031639283115509897, acc.: 100.0] [G loss: 0.0021840918343514204]\n",
      "1/1 [==============================] - 0s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "# Create a nested folder for the generated images\n",
    "# output_folder = './Data/fits_filtered2/generated_images6'\n",
    "output_folder = './Data/fits_filtered2/timeCounter'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Step 2: Load and Preprocess Dataset\n",
    "def load_images_from_folder(folder, image_size=(64, 64)):\n",
    "    images = []\n",
    "    valid_files = 0\n",
    "    invalid_files = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            img = load_img(os.path.join(folder, filename), target_size=image_size)\n",
    "            if img is not None:\n",
    "                images.append(img_to_array(img))\n",
    "                valid_files += 1\n",
    "            else:\n",
    "                invalid_files += 1\n",
    "        except (UnidentifiedImageError, OSError):\n",
    "            print(f\"Skipping file {filename}, as it is not a valid image.\")\n",
    "            invalid_files += 1\n",
    "    print(f\"Loaded {valid_files} valid images, skipped {invalid_files} invalid images.\")\n",
    "    return np.array(images)\n",
    "\n",
    "dataset = load_images_from_folder('./Data/fits_filtered2')\n",
    "print(f\"Dataset shape: {dataset.shape}\")\n",
    "if dataset.size == 0:\n",
    "    raise ValueError(\"No valid images found in the dataset. Please check the image files.\")\n",
    "dataset = (dataset - 127.5) / 127.5  # Normalize to [-1, 1]\n",
    "\n",
    "# Step 3: Build the GAN\n",
    "\n",
    "# Generator\n",
    "def build_generator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256 * 16 * 16, activation=\"relu\", input_dim=100))\n",
    "    model.add(layers.Reshape((16, 16, 256)))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.8))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "    model.add(layers.Conv2D(3, kernel_size=4, padding=\"same\"))\n",
    "    model.add(layers.Activation(\"tanh\"))\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def build_discriminator():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, input_shape=(64, 64, 3), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))  # New layer with more filters\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator()\n",
    "\n",
    "# The generator takes noise as input and generates images\n",
    "z = layers.Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model, only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model (stacked generator and discriminator)\n",
    "combined = tf.keras.Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n",
    "\n",
    "# Step 4: Train the GAN\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Training parameters\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "save_interval = 1000\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "X_train = dataset\n",
    "half_batch = int(batch_size / 2)\n",
    "\n",
    "# Training the GAN\n",
    "for epoch in range(epochs):\n",
    "    # Train Discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Train Generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid_y = np.array([1] * batch_size)\n",
    "\n",
    "    g_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "    print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % save_interval == 0:\n",
    "        noise = np.random.normal(0, 1, (25, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "        fig, axs = plt.subplots(5, 5)\n",
    "        cnt = 0\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                axs[i, j].imshow(gen_imgs[cnt])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.savefig(os.path.join(output_folder, f'epoch_{epoch}.png'))  # Save the figure\n",
    "        plt.close()  # Close the figure to free up memory\n",
    "\n",
    "# Step 5: Generate New Data\n",
    "\n",
    "noise = np.random.normal(0, 1, (10, 100))\n",
    "gen_imgs = generator.predict(noise)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5  # Rescale images 0 - 1\n",
    "\n",
    "for i in range(10):\n",
    "    plt.imshow(gen_imgs[i])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(output_folder, f'final_{i}.png'))  # Save the figure\n",
    "    plt.close()  # Close the figure to free up memory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
